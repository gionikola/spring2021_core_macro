{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggett (1993)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:53:41.789000-07:00",
     "start_time": "2021-05-25T00:53:38.479Z"
    }
   },
   "source": [
    "Load all necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:57:52.899000-07:00",
     "start_time": "2021-05-25T00:57:52.886Z"
    }
   },
   "outputs": [],
   "source": [
    "using Parameters\n",
    "using QuantEcon\n",
    "using Gadfly\n",
    "using LinearAlgebra\n",
    "using SparseArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:55:30.772000-07:00",
     "start_time": "2021-05-25T00:55:29.742Z"
    }
   },
   "outputs": [],
   "source": [
    "mutable struct Agent\n",
    "  σ::Float64\n",
    "  β::Float64\n",
    "  r::Float64\n",
    "  w::Float64\n",
    "  e::Vector{Float64} #vector of productivities\n",
    "  π::Vector{Float64}\n",
    "  agrid::Vector{Float64}\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:55:41.117000-07:00",
     "start_time": "2021-05-25T00:55:41.112Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility function for agent when consumption is a real number\n",
    "\"\"\"\n",
    "function utility(agent::Agent,c::Real)\n",
    "  σ = agent.σ\n",
    "  if c > 0\n",
    "    if σ == 1\n",
    "      return log(c)\n",
    "    else\n",
    "      return c^(1-σ)/(1-σ)\n",
    "    end\n",
    "  else\n",
    "    return -Inf\n",
    "  end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:55:51.837000-07:00",
     "start_time": "2021-05-25T00:55:51.838Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility function when consumption is a vector\n",
    "\"\"\"\n",
    "function utility(agent::Agent,cvec)\n",
    "  u(c) = utility(agent,c)\n",
    "  return u.(cvec)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:01.844000-07:00",
     "start_time": "2021-05-25T00:56:01.759Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  iterateBellman(agent::Agent,Vcont)\n",
    "\n",
    "Iterates on the bellman equation using continuation value function Vcont\n",
    "\"\"\"\n",
    "function iterateBellman(agent::Agent,Vcont)\n",
    "  @unpack σ,agrid,π,w,e,r,β = agent #unpack parameters of agent\n",
    "  u(c) = utility(agent,c)#shorthand for utility\n",
    "  Na = length(agrid)\n",
    "  S = length(e)\n",
    "\n",
    "  EVcont = Vcont*π #precompute expected value\n",
    "\n",
    "  #solve for each state\n",
    "  #preallocate space for V and a_policy\n",
    "  V = similar(Vcont)\n",
    "  a_policy = similar(Vcont,Int)\n",
    "  for s  in 1:S\n",
    "    for ia_ in 1:Na\n",
    "      cvec = e[s]*w + (1+r)*agrid[ia_] - agrid #possible consumption values for each asset position\n",
    "      obj = u(cvec) + β * EVcont #objective for each asset position\n",
    "\n",
    "      V[ia_,s],a_policy[ia_,s] = findmax(obj) #choose maximum asset position\n",
    "    end\n",
    "  end\n",
    "  return V,a_policy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:12.037000-07:00",
     "start_time": "2021-05-25T00:56:12.019Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  iterateBellman_alt(agent::Agent,Vcont)\n",
    "\n",
    "Iterates on the bellman equation using continuation value function Vcont.  Exploits\n",
    "that a_policy in increasing in a and that the value function is concave.\n",
    "\"\"\"\n",
    "function iterateBellman_alt(agent::Agent,Vcont)\n",
    "  @unpack σ,agrid,π,w,e,r,β = agent\n",
    "  u(c) = utility(agent,c)\n",
    "  Na = length(agrid)\n",
    "  S = length(e)\n",
    "  EVcont = Vcont*π #precompute expected value\n",
    "\n",
    "  EVcont = Vcont*π #precompute expected value\n",
    "\n",
    "  #solve for each state\n",
    "  #preallocate space for V and a_policy\n",
    "  V = similar(Vcont) #creates V the same size as Vcont\n",
    "  a_policy = similar(Vcont,Int) #note a_policy needs to be integers\n",
    "  for s  in 1:S\n",
    "    aprev = 1 #stores for the last ia_ the optimal policy\n",
    "    for ia_ in 1:Na\n",
    "      maxobj = -Inf #stores the maxobj up to this point\n",
    "      for ia in aprev:Na #start iterating at a_policy[ia_-1,s]\n",
    "        c = w*e[s] + (1+r)*agrid[ia_] - agrid[ia] #get consumption for this ia\n",
    "        obj = u(c) + β * EVcont[ia] #get objective\n",
    "        if obj >= maxobj #check if increasing ia improves utility\n",
    "          V[ia_,s],a_policy[ia_,s] = obj,ia #if so store values\n",
    "          maxobj = obj#and update maxobj\n",
    "        else\n",
    "          break #if it decreases utility end for loop, we have found our max\n",
    "        end\n",
    "      end\n",
    "      aprev = a_policy[ia_,s]#store the max in aprev for next ia_\n",
    "    end\n",
    "  end\n",
    "  return V,a_policy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:23.746000-07:00",
     "start_time": "2021-05-25T00:56:23.741Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  solveBellman(agent::Agent,V0,ϵ=1e-6)\n",
    "\n",
    "Solves the bellman equation for a given guess of V0 using iterateBellman\n",
    "\"\"\"\n",
    "function solveBellman(agent::Agent,V0,ϵ=1e-6)\n",
    "  Vcont = V0\n",
    "  a_policy = similar(V0,Int)\n",
    "  diff = 1.\n",
    "\n",
    "  while diff > ϵ\n",
    "    V,a_policy = iterateBellman(agent,Vcont)\n",
    "    diff = norm((V-Vcont)[:],Inf)\n",
    "    Vcont = V\n",
    "  end\n",
    "  return Vcont,a_policy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:31.827000-07:00",
     "start_time": "2021-05-25T00:56:31.819Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  solveBellman(agent::Agent,V0,ϵ=1e-6)\n",
    "\n",
    "Solves the bellman equation for a given guess of V0 using iterateBellman_alt\n",
    "\"\"\"\n",
    "function solveBellman_alt(agent::Agent,V0,ϵ=1e-6)\n",
    "  Vcont = V0\n",
    "  a_policy = similar(V0,Int)\n",
    "  diff = 1.\n",
    "\n",
    "  while diff > ϵ\n",
    "    V,a_policy = iterateBellman_alt(agent,Vcont)\n",
    "    diff = norm((V-Vcont)[:],Inf)\n",
    "    Vcont = V\n",
    "  end\n",
    "  return Vcont,a_policy\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:42.490000-07:00",
     "start_time": "2021-05-25T00:56:42.483Z"
    }
   },
   "outputs": [],
   "source": [
    "function constructTransitionMatrix(agent::Agent,a_policy)\n",
    "  @unpack π,agrid = agent\n",
    "\n",
    "  N = length(agrid)\n",
    "  S = length(π)\n",
    "\n",
    "  H = spzeros(N*S,N*S) #sparse matrix to save on space\n",
    "  for n_ in 1:N\n",
    "    for s in 1:S\n",
    "      i_ = n_+N*(s-1) # index for ia_,s\n",
    "      n = a_policy[n_,s]\n",
    "      for sprime in 1:S\n",
    "        i = n+N*(sprime-1)\n",
    "        #probability of transitioning from state ia_,s to ia,sprime\n",
    "        H[i_,i] = π[sprime]\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "  return H\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:56:49.892000-07:00",
     "start_time": "2021-05-25T00:56:49.886Z"
    }
   },
   "outputs": [],
   "source": [
    "function find_stationary_distribution(agent::Agent,a_policy)\n",
    "  H = constructTransitionMatrix(agent,a_policy)\n",
    "  N = size(H)[1]\n",
    "  π0 = ones(1,N)/N\n",
    "  diff = 1.\n",
    "  while diff > 1e-10\n",
    "    π1 = π0*H\n",
    "    diff = norm(π1-π0,Inf)\n",
    "    π0 = π1\n",
    "  end\n",
    "\n",
    "  return π0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:57:01.684000-07:00",
     "start_time": "2021-05-25T00:57:01.676Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  computeassetdemand(agent::Agent,r)\n",
    "\n",
    "Computes asset demanded in steady state at interest rate r and\n",
    "wage w\n",
    "\"\"\"\n",
    "function computeassetdemand(agent::Agent,r,w)\n",
    "  agent.r = r\n",
    "  agent.w = w\n",
    "\n",
    "  N = length(agent.agrid)\n",
    "  S = length(agent.e)\n",
    "  V0 = zeros(N,S)\n",
    "\n",
    "  V,a_policy = solveBellman_alt(agent,V0)\n",
    "  λss = find_stationary_distribution(agent,a_policy)\n",
    "\n",
    "  A = 0.\n",
    "  for n in 1:N\n",
    "    for s in 1:S\n",
    "      i = n + (s-1)*N\n",
    "      A  = A + λss[i] * agent.agrid[n]\n",
    "    end\n",
    "  end\n",
    "\n",
    "  λss = reshape(λss,N,S) #λss[ia_,s] is the fraction of agents with assets agrid[ia]\n",
    "  #and productivity e[s]\n",
    "\n",
    "  return dot(agent.agrid,sum(λss,dims=2)) #agrid*πss gives average assets for each productivity\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:57:59.287000-07:00",
     "start_time": "2021-05-25T00:57:58.221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00042094784010208216"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agent(2.,0.96,.02,1.,[.8,1.,1.2],ones(3)/3,LinRange(-.5,25.,1000))\n",
    "computeassetdemand(agent,.03435,1.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.4",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
